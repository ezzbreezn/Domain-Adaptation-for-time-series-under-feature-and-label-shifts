{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oxRVSk9f-jXc"
   },
   "outputs": [],
   "source": [
    "!pip install gdown -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVeHeEL9WZC-",
    "outputId": "60635e85-6fb1-4269-cac6-af28d7d1d78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TMj8Yh34tYQ3qXtDzQeTPwrrPOmSd5bf\n",
      "From (redirected): https://drive.google.com/uc?id=1TMj8Yh34tYQ3qXtDzQeTPwrrPOmSd5bf&confirm=t&uuid=0cd1fa75-9340-441b-b478-59d977680a40\n",
      "To: /home/jovyan/RAINCOAT/Data.zip\n",
      "100%|█████████████████████████████████████████| 469M/469M [00:04<00:00, 105MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1TMj8Yh34tYQ3qXtDzQeTPwrrPOmSd5bf\n",
    "!unzip -qo Data.zip -d datasets\n",
    "!rm -rf Data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNgG39Zm4YG7",
    "outputId": "d6c33300-f545-4ea4-ec71-9b1044506c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SASA'...\n",
      "remote: Enumerating objects: 47, done.\u001b[K\n",
      "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
      "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
      "remote: Total 47 (delta 18), reused 2 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (47/47), 12.13 MiB | 2.37 MiB/s, done.\n",
      "Resolving deltas: 100% (18/18), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/DMIRLAB-Group/SASA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Eo3MTyC4Qbn1"
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdgUTabGv2cC",
    "outputId": "d4a925e4-efd4-4c70-d0f1-c3574de733dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HAR batches tranposal: 100%|██████████| 60/60 [00:01<00:00, 32.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# For unknown reasons HAR's tensors have the shape of\n",
    "# [batch x features x timeseries], this fraction of the code swaps two last\n",
    "# dimensions to obtain coherent shape of [batch x timeseries x features]\n",
    "\n",
    "# If this and only this dataset fails, comment the code below\n",
    "\n",
    "FOLDER = './datasets/HAR'\n",
    "for file in tqdm(sorted(os.listdir(FOLDER)), desc=\"HAR batches tranposal\"):\n",
    "    filename = os.path.join(FOLDER, file)\n",
    "    batch = torch.load(filename, weights_only=False)\n",
    "    batch['samples'] = batch['samples'].transpose((0, 2, 1))\n",
    "    torch.save(batch, filename)\n",
    "    del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1fBT5hv77gH3"
   },
   "outputs": [],
   "source": [
    "def datasets_verification(datasets_dir : str):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(datasets_dir):\n",
    "        for filename in filenames:\n",
    "            if '.pt' in filename:\n",
    "                files.append(os.path.join(root, filename))\n",
    "\n",
    "    passed, failed = [], []\n",
    "    for file in tqdm(files, desc=\"Files verification\"):\n",
    "        tensor = torch.load(file, weights_only=False)\n",
    "        if tensor['samples'].shape[0] == tensor['labels'].shape[0]:\n",
    "            passed.append(file)\n",
    "        else:\n",
    "            failed.append(file)\n",
    "            print(f\"File '{file}' has failed the check.\")\n",
    "        del tensor\n",
    "\n",
    "    print()\n",
    "    print(f\"Passed:{len(passed):>4} ({len(passed)/len(files):.2%})\")\n",
    "    print(f\"Failed:{len(failed):>4} ({len(failed)/len(files):.2%})\")\n",
    "    print(f\" Total:{len(files):>4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_JfBowIFK_VZ"
   },
   "outputs": [],
   "source": [
    "def boiler_translator(source_folder : str, target_folder : str):\n",
    "    BATCH_SIZE = 128\n",
    "    SEQ_LENGTH = 36\n",
    "    STEP_LENGTH = SEQ_LENGTH\n",
    "\n",
    "    DEBUG = True\n",
    "\n",
    "    if not os.path.exists(target_folder): os.mkdir(target_folder)\n",
    "    # Get list of files, presplit by train/test\n",
    "    files = []\n",
    "    for root, dir, filenames in os.walk(source_folder):\n",
    "        for filename in filenames:\n",
    "            files.append(os.path.join(root, filename))\n",
    "    files = [file for file in files if '#' not in file]\n",
    "\n",
    "    index = {'train' : 0, 'test' : 0}\n",
    "    for file in files:\n",
    "        split_type = os.path.basename(file).split('.')[0]\n",
    "        data = pd.read_csv(file).iloc[:, 2:].to_numpy() # Remove timestamps and boilers' #\n",
    "        total = data.shape[0]\n",
    "        features, labels = [], []\n",
    "        # The last samples are truncated.\n",
    "        # The batch label is determined by the last one\n",
    "        for end_index in range(SEQ_LENGTH, total, STEP_LENGTH):\n",
    "            start_index = end_index - SEQ_LENGTH\n",
    "            features.append(data[start_index:end_index, :-1])\n",
    "            labels.append(data[end_index, -1])\n",
    "        features, labels = np.stack(features), np.stack(labels)\n",
    "\n",
    "\n",
    "        datapack = {}\n",
    "        for start_index in range(0, features.shape[0], BATCH_SIZE):\n",
    "            end_index = min(start_index + BATCH_SIZE, total)\n",
    "            datapack['samples'] = features[start_index:end_index, :, :]\n",
    "            datapack['labels'] = labels[start_index:end_index]\n",
    "            torch.save(datapack, os.path.join(target_folder, f\"{split_type}_{index[split_type]}.pt\"))\n",
    "            index[split_type] += 1\n",
    "            if DEBUG:\n",
    "                print(f\"| Samples shape: {datapack['samples'].shape}\", end='')\n",
    "                print(f\"\\t| Labels shape: {datapack['labels'].shape}\\t|\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaRBKto0yyxT",
    "outputId": "7bd96970-b791-40f1-b8bc-df8f1c287663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (116, 36, 20)\t| Labels shape: (116,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (82, 36, 20)\t| Labels shape: (82,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (107, 36, 20)\t| Labels shape: (107,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (44, 36, 20)\t| Labels shape: (44,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (72, 36, 20)\t| Labels shape: (72,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (128, 36, 20)\t| Labels shape: (128,)\t|\n",
      "| Samples shape: (113, 36, 20)\t| Labels shape: (113,)\t|\n"
     ]
    }
   ],
   "source": [
    "boiler_translator('./SASA/datasets/Boiler', './datasets/Boiler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "StC94K_uM5rd"
   },
   "outputs": [],
   "source": [
    "!rm -rf SASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_u46A3_7ckI",
    "outputId": "b3c63e55-dc59-46e3-c826-0172ae3ac5e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files verification: 100%|██████████| 250/250 [00:05<00:00, 47.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Passed: 250 (100.00%)\n",
      "Failed:   0 (0.00%)\n",
      " Total: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_verification('./datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-mmu_env]",
   "language": "python",
   "name": "conda-env-.mlspace-mmu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
